#!/usr/bin/env python3
"""
Serveur RAG minimaliste pour la recherche s√©mantique de citations.
Expose une API /search qui prend une query et retourne le top-N citations.
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
from sentence_transformers import SentenceTransformer
import chromadb
import json
from pathlib import Path
from typing import List, Dict, Tuple
import sys

app = Flask(__name__)
CORS(app)  # Permet les requ√™tes cross-origin depuis le front

# Configuration
EMBEDDER_MODEL = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
COLLECTION_NAME = "citations_mvp"
TOP_K_RETRIEVAL = 5  # Simplifi√©: pas de reranking
TOP_K_FINAL = 5

# Chargement global (au d√©marrage du serveur)
print("üîÑ Chargement des mod√®les...", file=sys.stderr)
embedder = SentenceTransformer(EMBEDDER_MODEL)
print("‚úÖ Mod√®les charg√©s", file=sys.stderr)

# Initialisation ChromaDB + indexation
print("üîÑ Indexation des citations...", file=sys.stderr)
# Utiliser l'√©chantillon pour un d√©marrage plus rapide
citations_path = Path(__file__).resolve().parents[1] / "citations_sample.json"
print(f"üìÇ Fichier: {citations_path}", file=sys.stderr)
with open(citations_path, 'r', encoding='utf-8') as f:
    data = json.load(f)
    citations = data if isinstance(data, list) else data.get("quotes", [])

# Garantir IDs uniques
seen_ids = {}
for idx, quote in enumerate(citations):
    base_id = quote.get("id")
    if base_id in (None, ""):
        base_id = f"cit_{idx}"
    
    dup_index = seen_ids.get(base_id, 0)
    seen_ids[base_id] = dup_index + 1
    
    quote_id = base_id if dup_index == 0 else f"{base_id}__dup{dup_index}"
    quote["id"] = quote_id

# Fonction d'enrichissement avec contexte s√©mantique approfondi
def create_enriched_text(quote: Dict) -> str:
    """Enrichit le texte avec auteur, cat√©gorie et mots-cl√©s √©motionnels pour am√©liorer la recherche s√©mantique."""
    text = (quote.get("text") or "").strip()
    author = (quote.get("author") or "").strip()
    category = (quote.get("category") or "").strip()
    
    # Le texte de la citation est le plus important
    parts = [text]
    
    # Ajouter la cat√©gorie de mani√®re s√©mantique pour am√©liorer la recherche
    if category:
        # Traduire les cat√©gories en contexte s√©mantique enrichi
        category_contexts = {
            "Amitie": "amiti√©, relations, soutien social",
            "Philosophie": "r√©flexion, sagesse, pens√©e profonde",
            "Amour": "sentiment amoureux, relation amoureuse, c≈ìur",
            "Revolution": "changement, transformation sociale",
            "Famille": "liens familiaux, proches, foyer",
            "Motivation": "encouragement, inspiration, d√©termination",
            "Tristesse": "m√©lancolie, chagrin, √©motion difficile",
            "Bonheur": "joie, contentement, bien-√™tre",
            "Travail": "m√©tier, carri√®re, activit√© professionnelle",
            "Vie": "existence, exp√©rience humaine",
            "Peur": "anxi√©t√©, stress, inqui√©tude, angoisse",
            "Colere": "frustration, irritation, rage, √©nervement",
            "Solitude": "isolement, seul, abandon",
            "Confiance": "foi, assurance, s√©curit√©",
            "Espoir": "optimisme, attente positive, avenir",
            "Doute": "incertitude, h√©sitation, questionnement",
            "Corps": "physique, sant√©, bien-√™tre corporel",
            "Perdre": "perte, absence, manque",
            "R√©ussite": "succ√®s, accomplissement, victoire",
            "√âchec": "d√©faite, difficult√©, revers",
        }
        context = category_contexts.get(category, category.lower())
        parts.append(f"Th√®me: {context}")
    
    if author and author != "internaute":
        parts.append(f"De {author}")
    
    return " | ".join(parts)

# Indexation
client = chromadb.Client()
try:
    client.delete_collection(name=COLLECTION_NAME)
except:
    pass

collection = client.create_collection(
    name=COLLECTION_NAME,
    metadata={"description": "Citations MVP avec recherche s√©mantique"}
)

ids = []
documents = []
metadatas = []
enriched_texts = []

for quote in citations:
    ids.append(quote['id'])
    original_text = quote.get('text', '')
    documents.append(original_text)
    
    # M√©tadonn√©es avec texte original pour l'affichage
    metadatas.append({
        "author": (quote.get("author") or ""),
        "category": (quote.get("category") or ""),
        "original_text": original_text  # Garder le texte brut pour l'affichage
    })
    
    enriched_texts.append(create_enriched_text(quote))

# Encoder les textes ENRICHIS
embeddings = embedder.encode(enriched_texts, show_progress_bar=False)
# Stocker les textes enrichis pour maintenir la coh√©rence avec les embeddings
collection.add(
    ids=ids,
    embeddings=embeddings.tolist(),
    documents=enriched_texts,  # ‚úÖ Textes enrichis pour coh√©rence s√©mantique
    metadatas=metadatas
)

print(f"‚úÖ {len(citations)} citations index√©es", file=sys.stderr)

@app.route('/search', methods=['POST'])
def search():
    """
    API de recherche s√©mantique.
    Body JSON: { 
        "query": "phrase de recherche", 
        "top_k": 5,
        "exclude_ids": ["id1", "id2", ...]  # IDs √† exclure (citations d√©j√† vues)
    }
    Retourne: { "results": [{ "id", "text", "score", "metadata" }, ...] }
    """
    try:
        data = request.get_json()
        query = data.get("query", "").strip()
        top_k = data.get("top_k", TOP_K_FINAL)
        exclude_ids = data.get("exclude_ids", [])
        
        if not query:
            return jsonify({"error": "Query manquante"}), 400
        
        # Valider exclude_ids
        if not isinstance(exclude_ids, list):
            exclude_ids = []
        exclude_ids_set = set(str(x) for x in exclude_ids if x)
        
        # Phase 1: Retrieval vectoriel
        # On r√©cup√®re plus de r√©sultats pour compenser les exclusions
        retrieval_count = min(TOP_K_RETRIEVAL + len(exclude_ids_set), len(citations))
        
        query_embedding = embedder.encode([query])[0]
        results = collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=retrieval_count
        )
        
        ids_list = results['ids'][0]
        documents_list = results['documents'][0]
        metadatas_list = results['metadatas'][0]
        distances_list = results.get('distances', [[]])[0]  # R√©cup√©rer les distances
        
        # Filtrer les IDs exclus
        filtered = []
        for i, (quote_id, doc, meta) in enumerate(zip(ids_list, documents_list, metadatas_list)):
            if quote_id not in exclude_ids_set:
                # Calculer le score de similarit√© depuis la distance L2 au carr√©
                # ChromaDB retourne des distances L2 squared (au carr√©)
                # Conversion en similarit√© : similarity ‚âà 1 / (1 + distance)
                distance = distances_list[i] if i < len(distances_list) else float('inf')
                similarity_score = 1.0 / (1.0 + distance) if distance < float('inf') else 0.0
                filtered.append((quote_id, doc, meta, similarity_score))
        
        # Pas de reranking pour le MVP: utiliser directement les top-k r√©sultats chromadb
        if not filtered:
            return jsonify({"results": []}), 200
        
        # Formatter la r√©ponse
        results_out = []
        for quote_id, text, metadata, score in filtered[:top_k]:
            # Utiliser le texte original pour l'affichage, pas le texte enrichi
            display_text = metadata.get('original_text', text)
            results_out.append({
                "id": quote_id,
                "text": display_text,
                "score": round(score, 4),  # Score r√©el de similarit√©
                "metadata": {
                    "author": metadata.get('author', ''),
                    "category": metadata.get('category', '')
                }
            })
        
        return jsonify({"results": results_out})
    
    except Exception as e:
        print(f"‚ùå Erreur: {e}", file=sys.stderr)
        return jsonify({"error": str(e)}), 500

@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint."""
    return jsonify({"status": "ok", "citations_count": len(citations)})

if __name__ == '__main__':
    print("\nüöÄ Serveur RAG d√©marr√© sur http://localhost:5001", file=sys.stderr)
    print("üìç Endpoint: POST /search avec { \"query\": \"...\" }\n", file=sys.stderr)
    app.run(host='127.0.0.1', port=5001, debug=False)
